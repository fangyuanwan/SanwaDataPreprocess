"""
å‹ç¼©æ—¶é—´å†»ç»“å†—ä½™è¡Œ / Compress Time Frozen Redundant Rows
ç§»é™¤è¿ç»­çš„ Time Static + Redundant è¡Œï¼Œåªä¿ç•™ç¬¬ä¸€è¡Œ

ç”¨é€”ï¼šè¿›ä¸€æ­¥å‹ç¼© Stage 6 è¾“å‡ºæ•°æ®
"""

import pandas as pd
from pathlib import Path
from config_pipeline import STAGE_6_FINAL, PROJECT_ROOT

# è¾“å‡ºç›®å½•
OUTPUT_DIR = STAGE_6_FINAL / "compressed"

def compress_time_frozen(df):
    """
    å‹ç¼©æ—¶é—´å†»ç»“å†—ä½™è¡Œ
    é€»è¾‘ï¼š
    1. è¿ç»­çš„ "Time Static" è¡Œ -> åªä¿ç•™ç¬¬ä¸€è¡Œ
    2. è¿ç»­çš„ "Redundant" è¡Œ -> åªä¿ç•™ç¬¬ä¸€è¡Œ
    3. "Time Frozen" è¡Œ -> åªä¿ç•™ç¬¬ä¸€è¡Œ
    """
    if df.empty:
        return df, []
    
    df = df.copy()
    df.sort_values(by='Filename', inplace=True)
    df.reset_index(drop=True, inplace=True)
    
    rows_to_keep = []
    deletion_log = []
    
    i = 0
    while i < len(df):
        current_row = df.iloc[i]
        current_time_status = str(current_row.get('Time_Status', ''))
        current_redundancy = str(current_row.get('Data_Redundancy', ''))
        
        # æ€»æ˜¯ä¿ç•™ç¬¬ä¸€è¡Œ
        rows_to_keep.append(i)
        
        # å¦‚æœå½“å‰è¡Œæ˜¯ "Time Static" æˆ–æœ‰ "Redundant" æ ‡è®°
        is_frozen_or_redundant = (
            'Time Static' in current_time_status or 
            'Time Frozen' in current_time_status or
            'Redundant' in current_redundancy
        )
        
        if is_frozen_or_redundant:
            # æŸ¥æ‰¾è¿ç»­çš„åŒç±»è¡Œ
            j = i + 1
            while j < len(df):
                next_row = df.iloc[j]
                next_time_status = str(next_row.get('Time_Status', ''))
                next_redundancy = str(next_row.get('Data_Redundancy', ''))
                
                # æ£€æŸ¥æ˜¯å¦ä¹Ÿæ˜¯å†»ç»“/å†—ä½™è¡Œ
                next_is_frozen = (
                    'Time Static' in next_time_status or 
                    'Time Frozen' in next_time_status or
                    'Redundant' in next_redundancy
                )
                
                # æ£€æŸ¥æ˜¯å¦æ˜¯åŒä¸€æ—¶é—´çŠ¶æ€åºåˆ—ï¼ˆROI_52æ—¶é—´æˆ³ç›¸åŒï¼‰
                same_plc_time = (
                    str(current_row.get('ROI_52', '')) == str(next_row.get('ROI_52', ''))
                )
                
                if next_is_frozen and same_plc_time:
                    # æ ‡è®°ä¸ºåˆ é™¤
                    deletion_log.append({
                        'Deleted_Filename': next_row['Filename'],
                        'Time_Status': next_time_status,
                        'Data_Redundancy': next_redundancy,
                        'ROI_52': next_row.get('ROI_52', ''),
                        'Reason': 'Time Frozen Compression'
                    })
                    j += 1
                else:
                    break
            
            # è·³åˆ°éå†—ä½™è¡Œ
            i = j
        else:
            i += 1
    
    # æå–ä¿ç•™çš„è¡Œ
    df_compressed = df.iloc[rows_to_keep].copy()
    
    return df_compressed, deletion_log

def process_final_csv(csv_path):
    """å¤„ç†å•ä¸ªæœ€ç»ˆCSVæ–‡ä»¶"""
    print(f"\nğŸ“‚ Processing: {csv_path.name}")
    
    try:
        df = pd.read_csv(csv_path)
    except Exception as e:
        print(f"   âŒ Error reading CSV: {e}")
        return
    
    original_count = len(df)
    print(f"   Original rows: {original_count}")
    
    # æ£€æŸ¥å¿…è¦çš„åˆ—
    required_cols = ['Filename', 'Time_Status', 'Data_Redundancy']
    missing_cols = [c for c in required_cols if c not in df.columns]
    if missing_cols:
        print(f"   âš ï¸ Missing columns: {missing_cols}")
        # å¦‚æœç¼ºå°‘åˆ—ï¼Œå¤åˆ¶åŸå§‹æ–‡ä»¶
        df.to_csv(OUTPUT_DIR / csv_path.name, index=False)
        return
    
    # å‹ç¼©
    df_compressed, deletion_log = compress_time_frozen(df)
    
    compressed_count = len(df_compressed)
    removed_count = original_count - compressed_count
    
    print(f"   Compressed rows: {compressed_count}")
    print(f"   Removed: {removed_count} ({removed_count/original_count*100:.1f}%)")
    
    # ä¿å­˜å‹ç¼©åçš„CSV
    output_name = csv_path.stem + "_Compressed.csv"
    df_compressed.to_csv(OUTPUT_DIR / output_name, index=False)
    print(f"   âœ… Saved: {output_name}")
    
    # ä¿å­˜åˆ é™¤æ—¥å¿—
    if deletion_log:
        log_name = csv_path.stem + "_Compression_Log.csv"
        pd.DataFrame(deletion_log).to_csv(OUTPUT_DIR / log_name, index=False)
        print(f"   ğŸ“‹ Log: {log_name}")

def main():
    print("\n" + "="*60)
    print("ğŸ—œï¸  TIME FROZEN COMPRESSION TOOL")
    print("="*60)
    
    print(f"\nğŸ“ Input Dir:  {STAGE_6_FINAL}")
    print(f"ğŸ“ Output Dir: {OUTPUT_DIR}")
    
    # åˆ›å»ºè¾“å‡ºç›®å½•
    OUTPUT_DIR.mkdir(parents=True, exist_ok=True)
    
    # æŸ¥æ‰¾æœ€ç»ˆCSVæ–‡ä»¶
    final_csvs = list(STAGE_6_FINAL.glob("*_Final.csv"))
    
    if not final_csvs:
        print("\nâŒ No *_Final.csv files found!")
        return
    
    print(f"\nğŸ” Found {len(final_csvs)} files to process")
    
    total_original = 0
    total_compressed = 0
    
    for csv_file in final_csvs:
        try:
            df_orig = pd.read_csv(csv_file)
            total_original += len(df_orig)
        except:
            pass
        process_final_csv(csv_file)
    
    # ç»Ÿè®¡å‹ç¼©åçš„æ€»è¡Œæ•°
    for csv_file in OUTPUT_DIR.glob("*_Compressed.csv"):
        try:
            df_comp = pd.read_csv(csv_file)
            total_compressed += len(df_comp)
        except:
            pass
    
    # ç»“æœ
    print("\n" + "="*60)
    print("ğŸ‰ COMPRESSION COMPLETE")
    print("="*60)
    if total_original > 0:
        print(f"   Total Original:   {total_original}")
        print(f"   Total Compressed: {total_compressed}")
        print(f"   Total Removed:    {total_original - total_compressed}")
        print(f"   Compression Rate: {(total_original - total_compressed)/total_original*100:.1f}%")
    print(f"\nğŸ“‚ Output: {OUTPUT_DIR}")
    print("="*60)

if __name__ == "__main__":
    main()
